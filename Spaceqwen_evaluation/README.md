# ğŸš€ SpaceQwen VQA Batch Evaluation

This script is used to batch evaluate the Qwen2.5-VL-3B-Instruct vision-language model on different datasets (CLEVR or SAT). It supports batch inference, result statistics, and saving results to JSON files.

## ğŸ› ï¸ Requirements

- ğŸ Python 3.8+
- ğŸ”¥ torch
- ğŸ¤— transformers
- â³ tqdm
- ğŸ–¼ï¸ PIL (Pillow)
- ğŸ“š datasets
- ğŸ› ï¸ (Custom) `data/process_dataset.py` and related dataset files

Install dependencies (if not already installed):

```bash
pip install torch transformers tqdm pillow datasets
```

Install Qwen2.5 package for huggingface

```bash
pip install git+https://github.com/huggingface/transformers accelerate
pip install qwen-vl-utils[decord]==0.0.8
```

## ğŸš¦ Usage

### 1ï¸âƒ£ Prepare Data

- ğŸ“¥ For CLEVR: The script will automatically download the dataset from HuggingFace.
- ğŸ“‚ For SAT: Place your SAT JSON and image files in the `data/SAT/` directory, or specify their paths with arguments.

### 2ï¸âƒ£ Run the Script

```bash
python test_spaceqwen_vqa_batch.py [OPTIONS]
```

#### âš™ï¸ Main Options

| Option                | Description                                                                                  | Default         |
|-----------------------|----------------------------------------------------------------------------------------------|-----------------|
| `--dataset`           | Dataset to test: `CLEVR` or `SAT`                                                            | CLEVR           |
| `--samples`           | Number of samples to test                                                                    | 20              |
| `--batch_size`        | Batch size for inference                                                                     | 1               |
| `--threshold`         | Threshold for small error in counting questions                                              | 1               |
| `--counting_only`     | Only test counting questions (flag, no value needed)                                         | False           |
| `--start_sample`      | Start testing from which sample (index)                                                      | 0               |
| `--sat_json`          | Path to SAT dataset JSON file (if not provided, uses `data/SAT/SAT_train_15000.json`)        | None            |
| `--sat_image_dir`     | Path to SAT image directory (if not provided, uses `data/SAT/`)                              | None            |

#### ğŸ§ª Example: Test CLEVR dataset

```bash
python test_spaceqwen_vqa_batch.py --dataset CLEVR --samples 100 --batch_size 4
```

#### ğŸ§ª Example: Test SAT dataset

```bash
python test_spaceqwen_vqa_batch.py --dataset SAT --sat_json data/SAT/SAT_train_15000.json --sat_image_dir data/SAT/ --samples 50
```

### 3ï¸âƒ£ Output

- ğŸ“Š Results and statistics will be saved in the `results/` directory as JSON files.
- ğŸ’¾ Interim results (every 10 samples) are saved in `results/interim/`.

### 4ï¸âƒ£ Notes

- ğŸ—‚ï¸ The script will automatically create `models/`, `data/`, and `results/` directories if they do not exist.
- ğŸ§© Make sure your custom dataset loader and processing functions are available in `data/process_dataset.py`.
- ğŸ¤— The script uses the HuggingFace model `"Qwen/Qwen2.5-VL-3B-Instruct"` by default.

---

## ğŸ“ File Structure

```
SpaceQwen_evaluation/
  test_spaceqwen_vqa_batch.py
  data/
    process_dataset.py
    SAT/
      SAT_train_15000.json
      [SAT images...]
  models/
  results/
```

---

## ğŸ“¬ Contact

For questions or issues, please open an issue in this repository.
